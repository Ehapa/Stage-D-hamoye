{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#convention for necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import optimizers\n\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import fbeta_score\nimport time\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Loading the  train csvs file and test csv file\ndf_train = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ndf_test = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlabels = df_train['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts = defaultdict(int) #dictionary containing each individual label\nfor l in labels:\n    for l2 in l:\n        counts[l2] += 1\n\n# data=[go.Bar(x=list(counts.keys()), y=list(counts.values()))]\n# layout=dict(height=800, width=800, title='Distribution of training labels')\n# fig=dict(data=data, layout=layout)\n# py.iplot(data, filename='train-label-dist')\n# plt.show()\ntag_list=list(counts.keys()) \ny=list(counts.values())\nsns.barplot(x=tag_list, y=y);\nplt.xlabel('labels');\nplt.xticks(rotation = 90);\nplt.title('Tag count for train set');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Explore test labels distribution\nlabels_test = df_test['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts_test = defaultdict(int)\nfor l in labels_test:\n    for l2 in l:\n        counts_test[l2] += 1\n\ntag_list_test=list(counts_test.keys()) \ntest_count=list(counts_test.values())\nsns.barplot(x=tag_list_test, y=test_count);\nplt.xlabel('labels');\nplt.xticks(rotation = 90);\nplt.title('Tag counts for test set');\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#this are some of the train images\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in df_train[:9].values:\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    #ax[i // 4, i % 4].show()\n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Create a dictionary assigning a numerical value to each label\nlabel_map = {i:j for j, i in enumerate(tag_list)}\nlabel_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# One hot encode the training labels. Convert the images into pixels and resize them\nX_train, Y_train = [], []\nfor img, label in tqdm(df_train.values, miniters = 1000):\n  target = np.zeros(17)\n  for tag in label.split(' '):\n    target[label_map[tag]]=1\n  X_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img)), (64,64)))\n  Y_train.append(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#convert the test images to pixels and resize them as well\nX_test=[]\nfor img, label in tqdm(df_test[:40669].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64,64)))\nfor img, label in tqdm(df_test[40669:].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64,64)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confirm the dimensions\nlen(X_test), len(X_train), len(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.getsizeof(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Change lists to numpy arrays and normalize\nx_train = np.array(X_train, np.float16)/255\ny_train = np.array(Y_train, np.uint8)\nx_test = np.array(X_test, np.float16)/255\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nyfull_test = []\nyfull_train = []\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n# f2_beta accuracy measure\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n \n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n \n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n \n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n \n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n \n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n        \n#Build a five layer CNN model\n\n#Create a path to save the weights\nkfold_weights_path = os.path.join('', 'weights_kfold_' + '.h5')\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(64, 64,3)))\nmodel.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(17, activation='sigmoid'))\n\n    \n\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Try a combination of epoch lengths and learning rates\nepochs = 20\nlearn_rate = 0.0001\nopt  = optimizers.Adam(lr=learn_rate)\nmodel.compile(loss='binary_crossentropy',optimizer=opt,metrics=[fbeta])\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n#    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)] #save the weights of the best performing model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, validation_data=(x_val, y_val),batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_test = model.predict(x_test, batch_size = 128, verbose=2) #save the test predictions\nyfull_test.append(p_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.array(yfull_test[0])\nfor i in range(1, len(yfull_test)):\n result += np.array(yfull_test[i])\nresult = pd.DataFrame(result, columns = tag_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the test images to pixels and resize them as well\nX_test=[]\nfor img, label in tqdm(df_test[:40669].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (32,32)))\nfor img, label in tqdm(df_test[40669:].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (32,32)))\n\nx_test = np.array(X_test, np.float16)/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x > 0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    pred.append(' '.join(list(a.index)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['tags'] = pred\ndf_test.to_csv('My_output.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}